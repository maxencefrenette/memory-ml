{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from typing import Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from math import log\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of file paths for all CSV files in the data/ folder\n",
    "csv_files = glob.glob('../data/*.csv')\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Read each CSV file into a DataFrame and append it to the list\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df[\"user\"] = file.split(\"/\")[-1].split(\".\")[0] # Extract the user name from the file path\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all the DataFrames in the list\n",
    "df = pd.concat(dfs)\n",
    "df = df[[\n",
    "    \"user\",\n",
    "    \"card_id\",\n",
    "    \"review_th\",\n",
    "    \"rating\",\n",
    "    \"delta_t\",\n",
    "]]\n",
    "\n",
    "print(f\"Data points: {len(df)}\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class ReviewsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset that provides access to the reviews data.\n",
    "\n",
    "    Features:\n",
    "    - delta_t_is_null: whether the delta_t is null\n",
    "    - delta_t: time since last review\n",
    "    - past_reviews:\n",
    "        - past_rating_is_null: whether the past rating is null\n",
    "        - past_rating: the rating of the past review\n",
    "        - past_delta_t_is_null: whether the past delta_t is null\n",
    "        - past_delta_t: the time since the past review\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, num_past_reviews: int) -> None:\n",
    "        self.df = df\n",
    "        self.num_past_reviews = num_past_reviews\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        row = self.df.iloc[index]\n",
    "\n",
    "        delta_t_is_null = int(row[\"delta_t\"] == -1)\n",
    "        delta_t = log(1 + row[\"delta_t\"]) if not delta_t_is_null else 0\n",
    "        rating = 0 if row[\"rating\"] == 1 else 1\n",
    "\n",
    "        past_reviews = []\n",
    "        for i in range(1, self.num_past_reviews + 1):\n",
    "            past_row = self.df.iloc[index - i]\n",
    "\n",
    "            if past_row[\"user\"] != row[\"user\"] or past_row[\"card_id\"] != row[\"card_id\"]:\n",
    "                past_reviews.append(\n",
    "                    [\n",
    "                        1,\n",
    "                        0,\n",
    "                        1,\n",
    "                        0,\n",
    "                    ]\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            past_rating_is_null = 0\n",
    "            past_rating = 0 if past_row[\"rating\"] == 1 else 1\n",
    "            past_delta_t_is_null = int(past_row[\"delta_t\"] == -1)\n",
    "            past_delta_t = log(1 + past_row[\"delta_t\"]) if not past_delta_t_is_null else 0\n",
    "\n",
    "            past_reviews.append(\n",
    "                [\n",
    "                    past_rating_is_null,\n",
    "                    past_rating,\n",
    "                    past_delta_t_is_null,\n",
    "                    past_delta_t,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        return (\n",
    "            torch.tensor([delta_t_is_null, delta_t] + sum(past_reviews, []), dtype=torch.float32, device=device),\n",
    "            torch.tensor([rating], dtype=torch.float32, device=device),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_reviews = 2\n",
    "epochs = 1\n",
    "train_size = 0.8\n",
    "test_size = 0.2\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2 + 4 * num_reviews, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class NNMemoryModel(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = NeuralNetwork()\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        pred = self.model(x)\n",
    "        loss = self.loss_fn(pred, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        pred = self.model(x)\n",
    "        loss = self.loss_fn(pred, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "\n",
    "# Create dataset\n",
    "dataset = ReviewsDataset(df, num_reviews)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, test_size]\n",
    ")\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "model = NNMemoryModel()\n",
    "wandb_logger = WandbLogger(project=\"Memory ML\")\n",
    "trainer = L.Trainer(max_epochs=epochs, logger=wandb_logger)\n",
    "trainer.fit(model, train_dataloader)\n",
    "trainer.test(model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memory-ml-QfZ3EAxj-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
